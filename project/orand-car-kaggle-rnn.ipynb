{"cells":[{"cell_type":"markdown","metadata":{"editable":false,"id":"o-4gbHFpmEay"},"source":["Let's go for RNN based on https://github.com/AbhishekAnand18/ImageTextRecognition/blob/master/ImageTextRecognition_Code.ipynb"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"id":"2mo7DBxomEaz","trusted":true},"outputs":[],"source":["# !pip install Pillow\n","import random\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","import cv2\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","from PIL import Image\n","from IPython.display import clear_output\n","import time\n","import os\n","from skimage.filters import threshold_local\n","import keras\n","import random\n","from keras import backend as K\n","#from skimage.morphology import skeletonize\n","import itertools\n","import datetime\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"editable":false,"id":"uzq19SMNmEa1","outputId":"655aa2c9-8796-4c5a-febd-fda69b45ddc7","trusted":true},"outputs":[],"source":["dir_path = '/kaggle/input/orand-car-dataset/ORAND-CAR-2014/'\n","CAR_A_test_images_path = dir_path + 'CAR-A/a_test_images/'\n","CAR_A_train_images_path = dir_path + 'CAR-A/a_train_images/'\n","CAR_B_test_images_path = dir_path + 'CAR-B/b_test_images/'\n","CAR_B_train_images_path = dir_path + 'CAR-B/b_train_images/'\n","\n","# def load_original_images():\n","#     images_path = []\n","#     for root, dirs, files in os.walk(dir_path):\n","#         for file in files:\n","#             if file.endswith('.png'):\n","#                 image_path = os.path.join(root, file)\n","#                 images_path.append(image_path.replace('\\\\','/'))\n","#     return images_path\n","\n","# images_path = load_original_images()\n","\n","def calculate_digit_count(label):\n","    return len(label)\n","\n","def get_labels(image_dir,text_path):\n","  with open(text_path,'r') as f :\n","    lines = f.readlines()\n","  listt = []\n","  for line in lines :\n","    parts = line.strip().split(\"\\t\")\n","    listt.append([image_dir + parts[0],parts[1]])\n","  DF = pd.DataFrame(listt)\n","  DF = DF.rename(columns={0: 'image_path', 1: 'label'})\n","  return DF\n","\n","def get_all_labels():\n","  CAR_A_test_text = dir_path + 'CAR-A/a_test_gt.txt'\n","  CAR_A_train_text = dir_path + 'CAR-A/a_train_gt.txt'\n","  CAR_B_test_text = dir_path + 'CAR-B/b_test_gt.txt'\n","  CAR_B_train_text = dir_path + 'CAR-B/b_train_gt.txt'\n","  a_test_label_df = get_labels(CAR_A_test_images_path,CAR_A_test_text)\n","  a_train_label_df = get_labels(CAR_A_train_images_path,CAR_A_train_text)\n","  b_test_label_df = get_labels(CAR_B_test_images_path,CAR_B_test_text)\n","  b_train_label_df = get_labels(CAR_B_train_images_path,CAR_B_train_text)\n","  all_labels = pd.concat([a_test_label_df , a_train_label_df , b_test_label_df , b_train_label_df],ignore_index=True)#.reset_index()\n","  return all_labels\n","\n","def reset_data():\n","  all_labels = get_all_labels()\n","  print(len(all_labels))\n","  print(len(all_labels['image_path'].unique())) # no dupicate image name\n","  # all_labels[\"actual_digit_count\"] = all_labels[\"label\"].astype(str).apply(calculate_digit_count)\n","  return all_labels\n","\n","all_labels = reset_data()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"editable":false,"id":"BGO5NvcRShCw","outputId":"e7b2aa46-3b4e-4160-c335-840189e9f664","trusted":true},"outputs":[],"source":["all_labels"]},{"cell_type":"markdown","metadata":{"editable":false,"id":"dOcNsJvLrAp0"},"source":["## Functionanl methods"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"id":"BfvtLTvLmEa1","trusted":true},"outputs":[],"source":["def get_size_dataFrame(all_labels,column):\n","    height_list = []\n","    width_list = []\n","    for image_path in all_labels[column]:\n","        height = Image.open(image_path).height\n","        width = Image.open(image_path).width\n","\n","        height_list.append(height)\n","        width_list.append(width)\n","\n","    sizes_df = pd.DataFrame({'width':width_list,'height':height_list})\n","    return sizes_df\n","\n","\n","def plot_random_image(image_label_df,from_path):\n","    random.seed(42)\n","    indices = list(range(len(image_label_df)))\n","    random.shuffle(indices)\n","\n","    for idx in indices[:10]+[21,22]:\n","        target_image = image_label_df[from_path][idx]\n","        print(\"label:\", image_label_df['label'][idx])\n","        print(\"target:\", target_image)\n","        image = mpimg.imread(target_image)\n","        plt.imshow(image)\n","        plt.show()\n","        time.sleep(2)\n","        clear_output(wait=True)\n","\n","\n","def convert_to_grayscale(df, from_path,new_dir_path):\n","    try:\n","        os.makedirs(new_dir_path)\n","    except:\n","        pass\n","\n","    for i, img_path in enumerate(df[from_path]):\n","        img = cv2.imread(img_path)\n","        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","        save_path = os.path.join(new_dir_path, f\"{i:05d}.png\")\n","        cv2.imwrite(save_path, gray_img)\n","\n","    df[new_dir_path] = [os.path.join(new_dir_path, f\"{i:05d}.png\") for i in range(len(df))]\n","\n","    return df\n","\n","\n","def denoise_images(df, from_path, new_dir_path):\n","    try:\n","        os.makedirs(new_dir_path)\n","    except:\n","        pass\n","\n","    for i, img_path in enumerate(df[from_path]):\n","        gray_img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n","        denoised_image = cv2.GaussianBlur(gray_img, (5, 5), 0)\n","        save_path = os.path.join(new_dir_path, f\"{i:05d}.png\")\n","        cv2.imwrite(save_path, denoised_image)\n","\n","    df[new_dir_path] = [os.path.join(new_dir_path, f\"{i:05d}.png\") for i in range(len(df))]\n","\n","    return df\n","\n","\n","def denoise_images_fastnlmeans(df, from_path, new_dir_path):\n","    try:\n","        os.makedirs(new_dir_path)\n","    except:\n","        pass\n","\n","    for i, img_path in enumerate(df[from_path]):\n","        gray_img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n","        denoised_img = cv2.fastNlMeansDenoising(gray_img, None, h=10, templateWindowSize=7, searchWindowSize=21)\n","        save_path = os.path.join(new_dir_path, f\"{i:05d}.png\")\n","        cv2.imwrite(save_path, denoised_img)\n","\n","    df[new_dir_path] = [os.path.join(new_dir_path, f\"{i:05d}.png\") for i in range(len(df))]\n","\n","    return df\n","\n","\n","def resize_images_with_height(df,from_path, new_dir_path, target_height):\n","    try:\n","        os.makedirs(new_dir_path)\n","    except:\n","        pass\n","\n","    for i, img_path in enumerate(df[from_path]):\n","        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n","        height, width = img.shape\n","        target_width = int(width * (target_height / height))\n","        resized_img = cv2.resize(img, (target_width, target_height))\n","        save_path = os.path.join(new_dir_path, f\"{i:05d}.png\")\n","        cv2.imwrite(save_path, resized_img)\n","\n","    df[new_dir_path] = [os.path.join(new_dir_path, f\"{i:05d}.png\") for i in range(len(df))]\n","    return df\n","\n","\n","def resize_images(df,from_path, new_dir_path, target_height,target_width):\n","    try:\n","        os.makedirs(new_dir_path)\n","    except:\n","        pass\n","\n","    for i, img_path in enumerate(df[from_path]):\n","        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n","        resized_img = cv2.resize(img, (target_width, target_height))\n","        save_path = os.path.join(new_dir_path, f\"{i:05d}.png\")\n","        cv2.imwrite(save_path, resized_img)\n","\n","    df[new_dir_path] = [os.path.join(new_dir_path, f\"{i:05d}.png\") for i in range(len(df))]\n","    return df\n","\n","def invert_images(df, from_path, new_dir_path):\n","    try:\n","        os.makedirs(new_dir_path)\n","    except:\n","        pass\n","    for i, img_path in enumerate(df[from_path]):\n","        bin_img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n","        inverted_img = cv2.bitwise_not(bin_img)\n","        save_path = os.path.join(new_dir_path, f\"{i:05d}.png\")\n","        cv2.imwrite(save_path, inverted_img)\n","\n","    df[new_dir_path] = [os.path.join(new_dir_path, f\"{i:05d}.png\") for i in range(len(df))]\n","    return df\n","\n","def binarize_images(df, from_path, new_dir_path):\n","    try:\n","        os.makedirs(new_dir_path)\n","    except:\n","        pass\n","\n","    for i, img_path in enumerate(df[from_path]):\n","        im = Image.open(img_path)\n","        im = np.array(im)\n","        _, binary_im = cv2.threshold(im, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n","        binary_im = Image.fromarray(binary_im)\n","        save_path = os.path.join(new_dir_path, f\"{i:05d}.png\")\n","        binary_im.save(save_path)\n","\n","    df[new_dir_path] = [os.path.join(new_dir_path, f\"{i:05d}.png\") for i in range(len(df))]\n","    return df\n","\n","def denoise_images_fastnlmeans(df, from_path, new_dir_path):\n","    try:\n","        os.makedirs(new_dir_path)\n","    except:\n","        pass\n","\n","    for i, img_path in enumerate(df[from_path]):\n","        gray_img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n","        denoised_img = cv2.fastNlMeansDenoising(gray_img, None, h=10, templateWindowSize=7, searchWindowSize=21)\n","        save_path = os.path.join(new_dir_path, f\"{i:05d}.png\")\n","        cv2.imwrite(save_path, denoised_img)\n","\n","    df[new_dir_path] = [os.path.join(new_dir_path, f\"{i:05d}.png\") for i in range(len(df))]\n","    return df\n","\n","\n","def denoise_images(df, from_path, new_dir_path):\n","    try:\n","        os.makedirs(new_dir_path)\n","    except:\n","        pass\n","\n","    for i, img_path in enumerate(df[from_path]):\n","        gray_img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n","        denoised_image = cv2.GaussianBlur(gray_img, (5, 5), 0)\n","        save_path = os.path.join(new_dir_path, f\"{i:05d}.png\")\n","        cv2.imwrite(save_path, denoised_image)\n","\n","    df[new_dir_path] = [os.path.join(new_dir_path, f\"{i:05d}.png\") for i in range(len(df))]\n","    return df\n","\n","def resize_with_padding(df, from_path, new_dir_path, target_height, target_width):\n","    try:\n","        os.makedirs(new_dir_path)\n","    except:\n","        pass\n","\n","    for i, img_path in enumerate(df[from_path]):\n","        gray_img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n","        aspect_ratio = (gray_img.shape[1] / gray_img.shape[0])\n","        new_height = target_height\n","        new_width = int(aspect_ratio * new_height)\n","\n","        resized_img = cv2.resize(gray_img, (new_width, new_height))\n","        if new_width < target_width:\n","            pad_width = target_width - new_width\n","            padded_img = cv2.copyMakeBorder(resized_img, 0, 0, 0, pad_width, cv2.BORDER_CONSTANT, value=255)\n","        else:\n","            padded_img = resized_img\n","\n","        save_path = os.path.join(new_dir_path, f\"{i:05d}.png\")\n","        cv2.imwrite(save_path, padded_img)\n","\n","    df[new_dir_path] = [os.path.join(new_dir_path, f\"{i:05d}.png\") for i in range(len(df))]\n","    return df\n","\n","def local_threshold_images(df, from_path, new_dir_path, block_size, offset):\n","    try:\n","        os.makedirs(new_dir_path)\n","    except:\n","        pass\n","    for i, img_path in enumerate(df[from_path]):\n","        # Read the image in grayscale\n","        gray_img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n","\n","        # Perform local thresholding using the threshold_local method from skimage\n","        binary_img = threshold_local(gray_img, block_size, offset=offset, method='gaussian', mode='reflect', cval=0)\n","\n","        # Convert the binary image to uint8 format (0 or 255)\n","        binary_img = (binary_img * 255).astype(np.uint8)\n","\n","        # Save the binary image\n","        save_path = os.path.join(new_dir_path, f\"{i:05d}.png\")\n","        cv2.imwrite(save_path, binary_img)\n","\n","    df[new_dir_path] = [os.path.join(new_dir_path, f\"{i:05d}.png\") for i in range(len(df))]\n","    return df\n","\n"]},{"cell_type":"markdown","metadata":{"editable":false,"id":"PnEwQxMkHWZa"},"source":["## Creating new images"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"id":"vj-coIRjHV1R","trusted":true},"outputs":[],"source":["import cv2\n","import pandas as pd\n","import numpy as np\n","from skimage import io, transform, util\n","from skimage.transform import rotate\n","from skimage.util import random_noise\n","\n","try:\n","    os.makedirs('/kaggle/working/created/')\n","except:\n","    pass\n","\n","augmentation_params = {\n","    'resize_range': (0.7, 1.4),\n","    'noise_var': 0.004,\n","    'rotate_angle_range': (-10, 10)\n","}\n","\n","new_data = {\n","    'image_path': [],\n","    'label': []\n","}\n","\n","for i in range(3):\n","  for index, row in all_labels.iterrows():\n","      label = row['label']\n","      # Check if the label contains any digit except 0\n","      if '0' not in label:\n","          image_path = row['image_path']\n","\n","          # Read the image\n","          img = io.imread(image_path, as_gray=True)\n","\n","          # Resize by random ratio\n","          ratio = np.random.uniform(*augmentation_params['resize_range'])\n","          resized_img = transform.rescale(img, scale=ratio, mode='constant')\n","\n","          # Rotate by a random angle\n","          angle = np.random.uniform(*augmentation_params['rotate_angle_range'])\n","          rotated_img = rotate(resized_img, angle, mode='edge')\n","\n","          # Add Gaussian noise\n","          noisy_img = random_noise(rotated_img, var=augmentation_params['noise_var'])\n","\n","          new_data['image_path'].append(noisy_img)\n","          new_data['label'].append(label)\n","\n","new_df = pd.DataFrame(new_data)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"trusted":true},"outputs":[],"source":["new_df"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"id":"kl7w2nIyc8HQ","trusted":true},"outputs":[],"source":["last_image = len(all_labels)\n","new_im_paths = [os.path.join('/kaggle/working/created/', f\"{i:05d}.png\") for i in range(last_image, last_image + len(new_df))]\n","new_im_labels = new_df['label']\n","for img_array, new_im_path in zip(new_df['image_path'], new_im_paths):\n","\n","    img_array = (img_array * 255).astype(np.uint8)\n","\n","    # Ensure image array has the correct shape (height x width)\n","    if len(img_array.shape) == 3:\n","        img_array = img_array[:, :, 0]  # Extract the first channel (grayscale)\n","\n","    # Save the grayscale image\n","    cv2.imwrite(new_im_path, img_array)\n","new_path_df = pd.DataFrame({'image_path': new_im_paths, 'label': new_im_labels})\n","all_labels = pd.concat([all_labels, new_path_df], ignore_index=True)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"editable":false,"id":"eJrOB6XFmEa4","outputId":"c94279ec-a86e-4da1-a882-318272734bc2","trusted":true},"outputs":[],"source":["all_labels"]},{"cell_type":"markdown","metadata":{"editable":false,"id":"Hrax4-LVmEa4"},"source":["## Preproccesing"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"id":"qOcy6QRXmEa4","trusted":true},"outputs":[],"source":["# Gray scale\n","all_labels = convert_to_grayscale(all_labels,'image_path','/kaggle/working/grayscaled/')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"editable":false,"id":"yOfCiK7Fdx2Y","outputId":"99b1c708-be65-4e21-9536-ff3828b97508","trusted":true},"outputs":[],"source":["# sizes_df = get_size_dataFrame(all_labels,'/kaggle/working/grayscaled/')\n","# sizes_df.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"id":"uKF2jFhAksfX","trusted":true},"outputs":[],"source":["# heights = sizes_df['height'].value_counts()\n","# value_counts_df = heights.reset_index()\n","# value_counts_df.columns = ['Value', 'Count']\n","# plt.bar(heights.index, heights.values)\n","# plt.xlabel('Unique Values')\n","# plt.ylabel('Count')\n","# plt.title('Count of Unique Values')\n","# plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"id":"YlN8Zp_SkuZN","trusted":true},"outputs":[],"source":["# widths = sizes_df['width'].value_counts()\n","# value_counts_df = widths.reset_index()\n","# value_counts_df.columns = ['Value', 'Count']\n","# plt.bar(widths.index, widths.values)\n","# plt.xlabel('Unique Values')\n","# plt.ylabel('Count')\n","# plt.title('Count of Unique Values')\n","# plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"id":"6VrqCYCuddNc","trusted":true},"outputs":[],"source":["# Denoising\n","all_labels = denoise_images_fastnlmeans(all_labels, '/kaggle/working/grayscaled/', '/kaggle/working/denoised_fastnlmeans/')\n","all_labels = denoise_images(all_labels, '/kaggle/working/denoised_fastnlmeans/', '/kaggle/working/denoised/')\n","\n","\n","# binarizing and inverting\n","# block_size = 53\n","# offset = 0\n","# all_labels = local_threshold_images(all_labels, '/kaggle/working/denoised_fastnlmeans/', '/kaggle/working/local/', block_size, offset)\n","all_labels = binarize_images(all_labels, '/kaggle/working/denoised/', '/kaggle/working/binarized/')\n","# all_labels = invert_images(all_labels, '/kaggle/working/denoised_fastnlmeans/', '/kaggle/working/inverted/')\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"id":"LSWVRZPCmEa4","trusted":true},"outputs":[],"source":["# resize to specific height\n","# target_height = 28\n","# all_labels = resize_images_with_height(all_labels,'./grayscaled/', './resized/', target_height)\n","all_labels = resize_with_padding(all_labels,'/kaggle/working/binarized/', '/kaggle/working/padded/',target_height=54,target_width=400)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"id":"ngkTtrG7muOb","trusted":true},"outputs":[],"source":["# all_labels = invert_images(all_labels, '/kaggle/working/inverted/', '/kaggle/working/inverted/')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":253},"editable":false,"id":"oiezZqikdrmO","outputId":"0dff42ff-267b-4dfb-af9d-26ecf7b30f7b","trusted":true},"outputs":[],"source":["plot_random_image(all_labels,'/kaggle/working/padded/')"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["# Shuffling Data (Necessery)"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"trusted":true},"outputs":[],"source":["all_labels = all_labels.sample(frac=1, random_state=42)"]},{"cell_type":"markdown","metadata":{"editable":false,"id":"3FRYsFDUmEa6"},"source":["## based on these two plots its better to resize images to 53*173"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"id":"QvJ5k_ewmEa6","trusted":true},"outputs":[],"source":["digits= '0123456789'\n","img_h=54\n","img_w=400\n","#image Channels\n","img_c=1\n","\n","# classes for softmax with number of letters +1 for blank space in ctc\n","num_classes=len(digits) +1\n","batch_size=64\n","max_length=8 # considering max length of ground truths labels to be 8"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"id":"VE5RTkR_mEa6","trusted":true},"outputs":[],"source":["def encode_numbers_labels(number):\n","    label_lst=[]\n","    for char in str(number):\n","        label_lst.append(digits.find(char)) # keeping 0 for blank and for padding labels\n","    return label_lst"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"id":"lhbqr4YRmEa6","trusted":true},"outputs":[],"source":["def numbers_from_labels(labels):\n","    txt=[]\n","    for ele in labels:\n","        if ele == len(digits): # CTC blank space\n","            txt.append(\"\")\n","        else:\n","            #print(letters[ele])\n","            txt.append(digits[ele])\n","    return \"\".join(txt)"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"id":"URhzfdB5mEa7","trusted":true},"outputs":[],"source":["def ctc_loss_function(args):\n","    y_pred, y_true, input_length, label_length = args\n","    y_pred = y_pred[:, 2:, :] # maybe need change based on my project and model architecture\n","    return K.ctc_batch_cost(y_true, y_pred, input_length, label_length)"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"id":"pCFXRGthmEa7","trusted":true},"outputs":[],"source":["from keras.layers import Input, Conv2D, MaxPool2D, Dense,MaxPooling2D\n","from keras.layers import AveragePooling2D, Flatten, Activation, Bidirectional\n","from keras.layers import BatchNormalization, Dropout\n","from keras.layers import Concatenate, Add, Multiply, Lambda\n","from keras.layers import UpSampling2D, Reshape\n","from keras.layers import add, concatenate\n","from keras.layers import Reshape\n","from keras.models import Model\n","from keras.layers import LSTM,GRU\n","import tensorflow as tf"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"id":"UPQcnAQSmEa7","trusted":true},"outputs":[],"source":["def Image_digit_recogniser_model_1(stage,drop_out_rate=0.425):\n","    img_h=54\n","    img_w=400\n","    if K.image_data_format() == 'channels_first':\n","        input_shape = (1, img_w, img_h)\n","    else:\n","        input_shape = (img_w, img_h, 1)\n","    model_input=Input(shape=input_shape,name='img_input',dtype='float32')\n","    \n","    #input shape is (400, 54, 1)  \n","    #input shape is (400, 54, 64)  \n","    #input shape is (200, 27, 64)  \n","    #input shape is (200, 27, 128)\n","    #input shape is (100, 13, 128)\n","    #input shape is (100, 13, 256)\n","    #input shape is (100, 6, 512)\n","    #input shape is (100, 3, 512)\n","    #input shape is (100, 1536)\n","    \n","    # Convolution layer\n","    model = Conv2D(64, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(model_input)\n","    model = BatchNormalization()(model)\n","    model = Activation('relu')(model)\n","    model = MaxPooling2D(pool_size=(2, 2), name='max1')(model)\n","\n","    model = Conv2D(128, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(model)\n","    model = BatchNormalization()(model)\n","    model = Activation('relu')(model)\n","    model = MaxPooling2D(pool_size=(2, 2), name='max2')(model)\n","\n","    model = Conv2D(256, (3, 3), padding='same', name='conv3', kernel_initializer='he_normal')(model)\n","    model = BatchNormalization()(model)\n","    model = Activation('relu')(model)\n","    model = Conv2D(256, (3, 3), padding='same', name='conv4', kernel_initializer='he_normal')(model)\n","    model=Dropout(drop_out_rate)(model)\n","    model = BatchNormalization()(model)\n","    model = Activation('relu')(model)\n","    model = MaxPooling2D(pool_size=(1, 3), name='max3')(model)\n","\n","    model = Conv2D(512, (3, 3), padding='same', name='conv5', kernel_initializer='he_normal')(model)\n","    model = BatchNormalization()(model)\n","    model = Activation('relu')(model)\n","    model = Conv2D(512, (3, 3), padding='same', name='conv6')(model)\n","    model=Dropout(drop_out_rate)(model)\n","    model = BatchNormalization()(model)\n","    model = Activation('relu')(model)\n","    model = MaxPooling2D(pool_size=(1, 2), name='max4')(model)\n","\n","    model = Conv2D(512, (2, 2), padding='same', kernel_initializer='he_normal', name='con7')(model)\n","    model=Dropout(0.325)(model)\n","    model = BatchNormalization()(model)\n","    model = Activation('relu')(model)\n","\n","    # CNN to RNN\n","    model = Reshape(target_shape=(100, 1024), name='reshape')(model)\n","\n","    model = Dense(96, activation='relu', kernel_initializer='he_normal', name='dense1')(model)\n","\n","    # RNN layer (LTSM)\n","    model=Bidirectional(LSTM(256, return_sequences=True, kernel_initializer='he_normal'), merge_mode='sum')(model)\n","    model=Bidirectional(LSTM(256, return_sequences=True, kernel_initializer='he_normal'), merge_mode='concat')(model)\n","\n","    # RNN layer (GRU)\n","    # model=Bidirectional(LSTM(256, return_sequences=True, kernel_initializer='he_normal'), merge_mode='sum')(model)\n","    # model=Bidirectional(LSTM(256, return_sequences=True, kernel_initializer='he_normal'), merge_mode='concat')(model)\n","\n","\n","\n","    # transforms RNN output to character activations:\n","    model = Dense(num_classes, kernel_initializer='he_normal',name='dense2')(model)\n","    y_pred = Activation('softmax', name='softmax')(model)\n","\n","\n","    labels = Input(name='ground_truth_labels', shape=[max_length], dtype='float32')\n","    input_length = Input(name='input_length', shape=[1], dtype='int64')\n","    label_length = Input(name='label_length', shape=[1], dtype='int64')\n","\n","    #CTC loss function\n","    loss_out = Lambda(ctc_loss_function, output_shape=(1,),name='ctc')([y_pred, labels, input_length, label_length]) #(None, 1)\n","\n","    if stage=='train':\n","        return model_input,y_pred,Model(inputs=[model_input, labels, input_length, label_length], outputs=loss_out)\n","    else:\n","        return Model(inputs=[model_input], outputs=y_pred)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"id":"2XmZMFAouVx8","trusted":true},"outputs":[],"source":["%pip install tensorflow-addons\n","import tensorflow_addons as tfa\n","radam=tfa.optimizers.RectifiedAdam()\n","from keras import optimizers\n","adam=optimizers.Adam()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"editable":false,"id":"53w-0o1tmEa7","outputId":"1d21a28e-e85a-47e3-9e90-f706332f8b60","trusted":true},"outputs":[],"source":["model_input,y_pred,img_digit_recog=Image_digit_recogniser_model_1('train')\n","test_func = K.function([model_input], [y_pred])\n","# img_digit_recog.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=adam)\n","img_digit_recog.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=radam)\n","img_digit_recog.summary()"]},{"cell_type":"markdown","metadata":{"editable":false,"id":"RfPKZ-EgmEa7"},"source":["# defining data generators"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"id":"dDkBoU4lmEa7","trusted":true},"outputs":[],"source":["class DataGenerator(keras.callbacks.Callback):\n","    def __init__(self, df, img_w, img_h, batch_size, max_number_len=8):\n","        self.img_h = img_h\n","        self.img_w = img_w\n","        self.batch_size = batch_size\n","        self.max_number_len = max_number_len\n","\n","        self.df = df\n","        self.n = len(df)\n","        self.indexes = list(range(self.n))\n","        self.cur_index = 0\n","        self.imgs = np.zeros((self.n, self.img_h, self.img_w))\n","        self.numbers = df['label'].tolist()  # Extract related labels from DataFrame\n","\n","\n","    def build_data(self):\n","        print(self.n, \" Image Loading start...\")\n","        for i, img_file in enumerate(self.df['/kaggle/working/padded/']):\n","            img = cv2.imread(img_file)\n","            img = img[:,:,1]                               #Extracting Single Channel Image\n","            img = cv2.resize(img, (self.img_w, self.img_h))\n","            img = img /255\n","            self.imgs[i, :, :]= img\n","            if i%5000==0:\n","                print(\"Loaded Images: \",i)\n","\n","        print(\"Number of Texts matches with Total Number of Images :\",len(self.numbers) == self.n)\n","        print(self.n, \" Image Loading finish...\")\n","\n","    def next_data(self):\n","        self.cur_index += 1\n","        if self.cur_index >= self.n:\n","            self.cur_index = 0\n","            random.shuffle(self.indexes)\n","        return self.imgs[self.indexes[self.cur_index]], self.numbers[self.indexes[self.cur_index]]\n","\n","    def next_batch(self):\n","        while True:\n","            X_data = np.ones([self.batch_size, self.img_w, self.img_h, 1])\n","            Y_data = np.ones([self.batch_size, self.max_number_len])* -1\n","            input_length = np.ones((self.batch_size, 1)) * 40\n","            label_length = np.zeros((self.batch_size, 1))                   #label length for CTC\n","            source_str=[]                                                   #List to store Ground Truth Labels\n","            for i in range(self.batch_size):\n","                img, text = self.next_data() #getting the image and text data pointed by current index\n","                                    #taking transpose of image\n","                img=img.T\n","                img = np.expand_dims(img, -1)  #expanding image to have a single channel\n","                X_data[i] = img\n","                label=encode_numbers_labels(text) # encoding label text to integer list and storing in temp label variable\n","                lbl_len=len(label)\n","                Y_data[i,0:lbl_len] = label #Storing the label till its length and padding others\n","                label_length[i] = len(label)\n","                source_str.append(text) #storing Ground Truth Labels which will be accessed as reference for calculating metrics\n","\n","        #Preparing the input for the Model\n","            inputs = {\n","                'img_input': X_data,\n","                'ground_truth_labels': Y_data,\n","                'input_length': input_length,\n","                'label_length': label_length,\n","                'source_str': source_str  # used for visualization only\n","            }\n","            #Preparing output for the Model and intializing to zeros\n","            outputs = {'ctc': np.zeros([self.batch_size])}\n","            yield (inputs, outputs) # Return the Prepared input and output to the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"id":"eYbwKGvZbs2d","trusted":true},"outputs":[],"source":["test_set_precentage = int(len(all_labels) * 0.8)\n","val_set_precentage = int(len(all_labels) * 0.7 // 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"editable":false,"id":"QyKng_GsnCyM","outputId":"fd7031f5-b457-463e-8160-096349096efc","trusted":true},"outputs":[],"source":["test_set_precentage,val_set_precentage"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"editable":false,"id":"r5wr7dwXmEa8","outputId":"cb192988-1ca9-4e0c-cfff-31b838f6ab1a","trusted":true},"outputs":[],"source":["train_gene = DataGenerator(all_labels[:val_set_precentage], img_w, img_h, batch_size, max_number_len=8)\n","train_gene.build_data()\n","train_num_batches=int(train_gene.n / batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"editable":false,"id":"l4aGuD27mEa8","outputId":"47cc2e7f-76ef-40f4-891d-3bcadfe878ee","trusted":true},"outputs":[],"source":["val_gen=DataGenerator(all_labels[val_set_precentage:test_set_precentage], img_w, img_h, batch_size, max_number_len=8)\n","val_gen.build_data()\n","val_num_batches=int(val_gen.n / batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"id":"z2HttGl6mEa8","trusted":true},"outputs":[],"source":["def decode_batch(test_func, number_batch):\n","    out = test_func([number_batch])[0] #returns the predicted output matrix of the model\n","    ret = []\n","    for j in range(out.shape[0]):\n","        out_best = list(np.argmax(out[j, 2:], 1))\n","        out_best = [k for k, g in itertools.groupby(out_best)]\n","        outstr = numbers_from_labels(out_best)\n","        ret.append(outstr)\n","    return ret"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"id":"b10F3rgCmEa8","trusted":true},"outputs":[],"source":["def accuracies(actual_labels,predicted_labels,is_train):\n","    accuracy=0\n","    letter_acc=0\n","    letter_cnt=0\n","    count=0\n","    for i in range(len(actual_labels)):\n","        predicted_output=predicted_labels[i]\n","        actual_output=actual_labels[i]\n","        count+=1\n","        for j in range(min(len(predicted_output),len(actual_output))):\n","            if predicted_output[j]==actual_output[j]:\n","                letter_acc+=1\n","        letter_cnt+=max(len(predicted_output),len(actual_output))\n","        if actual_output==predicted_output:\n","            accuracy+=1\n","    final_accuracy=np.round((accuracy/len(actual_labels))*100,2)\n","    final_letter_acc=np.round((letter_acc/letter_cnt)*100,2)\n","    return final_accuracy,final_letter_acc"]},{"cell_type":"markdown","metadata":{"editable":false,"id":"mVlHWdrAmEa8"},"source":["## callback visualizer"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"id":"wJ4Awe13mEa8","trusted":true},"outputs":[],"source":["class VizCallback(keras.callbacks.Callback):\n","    \"\"\"\n","    The Custom Callback created for printing the Accuracy and Letter Accuracy Metrics at the End of Each Epoch\n","    \"\"\"\n","\n","    def __init__(self, test_func, text_img_gen,is_train,acc_compute_batches):\n","        self.test_func = test_func\n","        self.text_img_gen = text_img_gen\n","        self.is_train=is_train                #used to indicate whether the callback is called to for Train or Validation Data\n","        self.acc_batches=acc_compute_batches  # Number of Batches for which the metrics are computed typically equal to steps/epoch\n","\n","    def show_accuracy_metrics(self,num_batches):\n","        \"\"\"\n","        Calculates the accuracy and letter accuracy for each batch of inputs,\n","        and prints the avarage accuracy and letter accuracy across all the batches\n","        \"\"\"\n","        accuracy=0\n","        letter_accuracy=0\n","        batches_cnt=num_batches\n","        while batches_cnt>0:\n","            number_batch = next(self.text_img_gen)[0]   #Gets the next batch from the Data generator\n","            decoded_res = decode_batch(self.test_func,number_batch['img_input'])\n","            actual_res=number_batch['source_str']\n","            acc,let_acc=accuracies(actual_res,decoded_res,self.is_train)\n","            accuracy+=acc\n","            letter_accuracy+=let_acc\n","            batches_cnt-=1\n","        accuracy=accuracy/num_batches\n","        letter_accuracy=letter_accuracy/num_batches\n","        if self.is_train:\n","            print(\"\\nTrain Average Accuracy of \"+str(num_batches)+\" Batches: \",np.round(accuracy,2),\" %\")\n","            print(\"Train Average Letter Accuracy of \"+str(num_batches)+\" Batches: \",np.round(letter_accuracy,2),\" %\")\n","        else:\n","            print(\"Validation Average Accuracy of \"+str(num_batches)+\" Batches: \",np.round(accuracy,2),\" %\")\n","            print(\"Validation Average Letter Accuracy of \"+str(num_batches)+\" Batches: \",np.round(letter_accuracy,2),\" %\")\n","\n","\n","    def on_epoch_end(self, epoch, logs={}):\n","        self.show_accuracy_metrics(self.acc_batches)"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"id":"T4UX-ztHmEa9","trusted":true},"outputs":[],"source":["from keras.callbacks import EarlyStopping,ModelCheckpoint\n","early_stop=EarlyStopping(monitor='val_loss',patience=2,restore_best_weights=True)\n","model_chk_pt=ModelCheckpoint('weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', save_best_only=False,save_weights_only=True,verbose=0, mode='auto', period=2)\n","logdir = os.path.join(\"logs_127\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"id":"HCjAIohimEa9","trusted":true},"outputs":[],"source":["%load_ext tensorboard\n","%tensorboard --logdir logs_127\n","clear_output()"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"id":"p3K33p1ZmEa9","trusted":true},"outputs":[],"source":["viz_cb_train = VizCallback( test_func, train_gene.next_batch(),True,train_num_batches)\n","viz_cb_val = VizCallback( test_func, val_gen.next_batch(),False,val_num_batches)"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"trusted":true},"outputs":[],"source":["new_df = None\n","sizes_df = None\n","heights = None\n","widths = None\n","# all_labels.drop(['./grayscaled/'])\n","# remove_directory('/content/grayscaled/')\n","# remove_directory('/content/denoised/')\n","# remove_directory('/content/created/')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"editable":false,"id":"1Q3bsRqhmEa9","outputId":"d8bdd911-afd2-4740-fc43-a99ba4a543d8","trusted":true},"outputs":[],"source":["history = img_digit_recog.fit(\n","    train_gene.next_batch(),\n","    steps_per_epoch=int(train_gene.n / batch_size),\n","    epochs=30,\n","    callbacks=[viz_cb_train, viz_cb_val, train_gene, val_gen, tensorboard_callback, early_stop, model_chk_pt],\n","    validation_data=val_gen.next_batch(),\n","    validation_steps=int(val_gen.n / batch_size)\n",")\n","img_digit_recog.save(\"model_16.h5\")\n","print(\"model saved\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"id":"FgSoPyi2tm_c","trusted":true},"outputs":[],"source":["plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Model Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend(['Train', 'Validation'], loc='upper right')\n","plt.show()\n","\n"]},{"cell_type":"markdown","metadata":{"editable":false,"id":"uAni2PPnuivb"},"source":["## now measure our model on test dataset\n","\n","actually we dont have dataset\n","\n","so we can use new data or train out model on smaller dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"id":"xbbEUvAevBmG","trusted":true},"outputs":[],"source":["def decode_label(out):\n","    out_best = list(np.argmax(out[0,2:], axis=1))\n","\n","    out_best = [k for k, g in itertools.groupby(out_best)]  # remove overlap value\n","\n","    outstr=numbers_from_labels(out_best)\n","    return outstr"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"id":"7Y3T6YsW-3hF","trusted":true},"outputs":[],"source":["model=Image_digit_recogniser_model_1('predict')\n","# model = keras.models.load_model('first_model.h5',compile=False)\n","model.load_weights('model_16.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"id":"t2imGbXlZLLf","trusted":true},"outputs":[],"source":["test_data = all_labels[test_set_precentage:]\n","val_img_names=test_data['/kaggle/working/padded/'].values\n","val_labels=test_data['label'].values"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"trusted":true},"outputs":[],"source":["def single_image_resizer_with_padding(image_array, target_height, target_width):\n","    gray_img = image_array\n","    aspect_ratio = (gray_img.shape[1] / gray_img.shape[0]) * 1.1\n","    new_height = target_height\n","    new_width = int(aspect_ratio * new_height)\n","\n","    resized_img = cv2.resize(gray_img, (new_width, new_height))\n","    if new_width < target_width:\n","        pad_width = target_width - new_width\n","        padded_img = cv2.copyMakeBorder(resized_img, 0, 0, 0, pad_width, cv2.BORDER_CONSTANT, value=255)\n","    else:\n","        padded_img =  cv2.resize(resized_img, (target_width, target_height))\n","\n","    return padded_img"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"id":"SFUs5KstJEbg","trusted":true},"outputs":[],"source":["def test_data_output_Prediction(model, test_img_names, test_labels):\n","    num_classes = 10  # Assuming there are 10 digits (0 to 9)\n","    accuracy = 0\n","    letter_acc = [0] * num_classes\n","    letter_total = [0] * num_classes\n","    count = 0\n","    all_predicted = []\n","    letter_mis_match = []\n","\n","    for i in range(len(test_labels)):\n","        test_img = cv2.imread(test_img_names[i])\n","        test_image = single_image_resizer_with_padding(test_img,54,400)\n","        # print(\"1 :\",test_image.shape)\n","        test_image = test_image[:, :, 1]\n","        # print(\"2 :\",test_image.shape)\n","        test_image = test_image.T\n","        # print(\"3 :\",test_image.shape)\n","        test_image = np.expand_dims(test_image, axis=-1)\n","        # print(\"4 :\",test_image.shape)\n","        test_image = np.expand_dims(test_image, axis=0)\n","        # print(\"5 :\",test_image.shape)\n","        test_image = test_image / 255\n","        model_output = model.predict(test_image, verbose=-1)\n","        predicted_output = decode_label(model_output)\n","        # print(\"output :\",predicted_output)\n","        actual_output = test_labels[i]\n","        all_predicted.append([test_img_names[i], predicted_output])\n","        count += 1\n","        mis_match = 0\n","\n","        for j in range(min(len(predicted_output), len(actual_output))):\n","            if predicted_output[j] == actual_output[j]:\n","                letter_acc[int(predicted_output[j])] += 1\n","            else:\n","                mis_match += 1\n","            letter_total[int(actual_output[j])] += 1\n","\n","        letter_mis_match.append(mis_match)\n","        if actual_output == predicted_output:\n","            accuracy += 1\n","\n","        if (count % 400) == 0:\n","            print(\"Processed\", count, \"Images\")\n","\n","    digit_accuracy = [acc / total if total > 0 else 0 for acc, total in zip(letter_acc, letter_total)]\n","    return accuracy, letter_acc, letter_total, digit_accuracy, letter_mis_match, all_predicted"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"id":"SusSl3TmvI4Q","trusted":true},"outputs":[],"source":["synth_val_accuracy,letter_acc,synth_val_letter_acc,synth_val_letter_cnt,synth_val_mis_match,all_predicted=test_data_output_Prediction(model,val_img_names,val_labels)\n","synth_val_accuracy,letter_acc,synth_val_letter_acc,synth_val_letter_cnt#,synth_val_mis_match\n"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"id":"oAJf3ElZceJ0","trusted":true},"outputs":[],"source":["true_list = []\n","for i in range(len(all_labels['label'].iloc[test_set_precentage:])):\n","  if str(all_labels['label'].iloc[test_set_precentage + i]) == str(all_predicted[i][1]):\n","    true_list.append(1)\n","  else:\n","    print(all_labels['label'].astype(str).iloc[test_set_precentage + i],\" == \",all_predicted[i][1],\"image -->\",all_predicted[i][0])\n","    true_list.append(0)\n","trues = pd.DataFrame(true_list)\n","trues[0].describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"trusted":true},"outputs":[],"source":["def remove_last_digit_if_one(predicted_outputs):\n","    cleaned_outputs = []\n","    for output in predicted_outputs:\n","        #if output[1][-1] == '2' and  output[1][-2] == '9':\n","        if output[1][-1] == '1':\n","             #cleaned_outputs.append([output[0],output[1][:-2]])\n","            cleaned_outputs.append([output[0],output[1][:-1]])\n","        else:\n","            cleaned_outputs.append([output[0],output[1]])\n","    return cleaned_outputs\n","\n","all_predicted = remove_last_digit_if_one(all_predicted)"]},{"cell_type":"markdown","metadata":{"editable":false,"id":"MAbzD_4ftSLe"},"source":["As can be seen, due to the large number of zeros in the training dataset, most of the prediction errors have been replaced by zeros"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"id":"PX_3mjE6NNBH","trusted":true},"outputs":[],"source":["pre_digits_df = pd.DataFrame(letter_acc)\n","pre_digits_df.append({0:0},ignore_index=True)\n","\n","\n","all_digits = []\n","for i in all_labels['label'].iloc[test_set_precentage:]:\n","  for ii in i:\n","    all_digits.append(ii)\n","print(len(all_digits))\n","digits_df = pd.DataFrame(all_digits)\n","digits_df.append({0:0},ignore_index=True)\n","digit_counts = digits_df[0]\n","\n","digit_counts = pd.DataFrame(digit_counts)\n","digit_counts = digit_counts[0].value_counts()\n","digit_counts = pd.DataFrame(digit_counts)\n","\n","\n","df1 = digit_counts.sort_index()\n","df2 = pre_digits_df.sort_index()\n","\n","# Create a figure and axis\n","fig, ax = plt.subplots()\n","\n","# Plot the data for the first dataframe\n","ax.bar(df1.index, df1[0], width=0.4, align='center', label='actual')\n","\n","# Plot the data for the second dataframe (shifted by 0.4 for side-by-side comparison)\n","ax.bar(df2.index + 0.4, df2[0], width=0.4, align='center', label='predicted')\n","\n","# Set labels and title\n","ax.set_xlabel('Digit')\n","ax.set_ylabel('Count')\n","ax.set_title('Comparison of Digit Counts')\n","ax.set_xticks(df1.index)\n","ax.legend()\n","\n","# Show the plot\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["## Exploring all digits count in our main dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"trusted":true},"outputs":[],"source":["all_digits = []\n","for i in all_labels['label']:\n","  for ii in i:\n","    all_digits.append(ii)\n","print(len(all_digits))\n","digits_df = pd.DataFrame(all_digits)"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"id":"51v4Dvgc685Q","trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# Calculate the frequency of each digit\n","digit_counts = digits_df[0].value_counts()\n","\n","# Plot the count of each digit\n","plt.figure(figsize=(10, 6))\n","digit_counts.plot(kind='bar')\n","plt.title('Count of Each Digit')\n","plt.xlabel('Digit')\n","plt.ylabel('Count')\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["## load DIDA into dataframe"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"trusted":true},"outputs":[],"source":["dida_images_dir_path = '/kaggle/input/DIDA-for-test/DIDA_1/'\n","import pandas as pd\n","dida_labels_dir_path = '/kaggle/input/dida-labels/DIDA_12000_String_Digit_Labels.csv'\n","your_header = ['image_name', 'label']\n","dida_labels = pd.read_csv(dida_labels_dir_path)\n","dida_labels.columns = your_header\n","\n","\n","dida_labels['image_name'] = dida_labels['image_name'].astype(str)\n","dida_labels['label'] = dida_labels['label'].astype(str)\n","dida_paths = []\n","for row in dida_labels['image_name'].astype(str) :\n","    full_path = dida_images_dir_path + row + '.jpg'\n","    dida_paths.append(full_path)\n","dida_labels['image_path'] = dida_paths\n","dida_labels.drop(columns=['image_name'], inplace=True)\n","dida_labels\n","\n","dida_sample = dida_labels.sample(n=500, random_state=42)\n","dida_sample"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"trusted":true},"outputs":[],"source":["# image = cv2.imread(dida_images_dir_path + '362.jpg')\n","# image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","# plt.imshow(image_rgb)\n","# plt.axis('off')  # Turn off axis labels\n","# plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"trusted":true},"outputs":[],"source":["dida_sample"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"trusted":true},"outputs":[],"source":["def preprocess_and_save_images(df, from_path, new_dir_path):\n","    try:\n","        os.makedirs(new_dir_path)\n","    except:\n","        pass\n","\n","    for i, path in enumerate(df[from_path]):\n","        im_g = cv2.imread(path, cv2.IMREAD_GRAYSCALE)  \n","        im_g = cv2.fastNlMeansDenoising(im_g, None, 10, 7, 21)\n","        im_g = cv2.GaussianBlur(im_g, (5, 5), 0) \n","        _, im_g = cv2.threshold(im_g, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)  \n","        target_height = 54\n","        target_width = 400 \n","        aspect_ratio = (im_g.shape[1] / im_g.shape[0])\n","        new_height = target_height\n","        new_width = int(aspect_ratio * new_height)\n","        resized_im_g = cv2.resize(im_g,(new_width, new_height))\n","        if new_width < target_width:\n","            pad_width = target_width - new_width\n","            padded_im_g = cv2.copyMakeBorder(resized_im_g, 0, 0, 0, pad_width, cv2.BORDER_CONSTANT, value=255)\n","        else:\n","            padded_im_g = resized_img\n","\n","        save_path = os.path.join(new_dir_path, f\"{i:05d}.png\")\n","        cv2.imwrite(save_path, padded_im_g)\n","\n","    df[new_dir_path] = [os.path.join(new_dir_path, f\"{i:05d}.png\") for i in range(len(df))]\n","    return df\n","\n","\n","dida_sample = preprocess_and_save_images(dida_sample, 'image_path','dida')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"trusted":true},"outputs":[],"source":["plot_random_image(dida_sample,'don')"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"trusted":true},"outputs":[],"source":["test_data = dida_sample\n","dida_img_names=test_data['don'].values\n","dida_labels=test_data['label'].values"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"trusted":true},"outputs":[],"source":["synth_val_accuracy,letter_acc,synth_val_letter_acc,synth_val_letter_cnt,synth_val_mis_match,all_predicted=test_data_output_Prediction(model,dida_img_names,dida_labels)\n","synth_val_accuracy,letter_acc,synth_val_letter_acc,synth_val_letter_cnt#,synth_val_mis_match\n"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"trusted":true},"outputs":[],"source":["true_list = []\n","for i in range(len(dida_sample)):\n","  if str(dida_sample['label'].iloc[i]) == str(all_predicted[i][1]):\n","    true_list.append(1)\n","    print(dida_sample['label'].astype(str).iloc[i],\" == \",all_predicted[i][1],\"image -->\",all_predicted[i][0])\n","  else:\n","    true_list.append(0)\n","trues = pd.DataFrame(true_list)\n","trues[0].describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"trusted":true},"outputs":[],"source":["all_predicted"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"trusted":true},"outputs":[],"source":["image = mpimg.imread('/kaggle/input/DIDA-for-test/DIDA_1/5405.jpg')\n","print(\"image : \",image)\n","plt.imshow(image)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false},"outputs":[],"source":[]}],"metadata":{"accelerator":"TPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
